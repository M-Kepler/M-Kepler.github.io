{"uid":"661c2ff54a56dcb2","name":"test_xiaohongshu_title","fullName":"lib.llm.kimi.test_kimi#test_xiaohongshu_title","historyId":"b19eea8f91f208adf3ee4536c27979a9","time":{"start":1713494260867,"stop":1713494350323,"duration":89456},"status":"broken","statusMessage":"tenacity.RetryError: RetryError[<Future at 0x7fb592e4f790 state=finished raised RateLimitError>]","statusTrace":"self = <Retrying object at 0x7fb58363a6a0 (stop=<tenacity.stop.stop_after_attempt object at 0x7fb583631550>, wait=<tenacity.w...0x7fb583622b50>, before=<function before_nothing at 0x7fb5855b2ee0>, after=<function after_nothing at 0x7fb5855b91f0>)>\nfn = <function OpenAIBaseHelper.chat at 0x7fb583636310>\nargs = (<mypy.lib.llm.kimi.helper.KimiHelper object at 0x7fb5933230d0>,)\nkwargs = {}\nretry_state = <RetryCallState 140417835979584: attempt #5; slept for 36.0; last result: failed (RateLimitError Error code: 429 - {'error': {'message': 'The engine is currently overloaded, please try again later', 'type': 'engine_overloaded_error'}})>\ndo = <tenacity.DoAttempt object at 0x7fb592e4fac0>\n\n    def __call__(\n        self,\n        fn: t.Callable[..., WrappedFnReturnT],\n        *args: t.Any,\n        **kwargs: t.Any,\n    ) -> WrappedFnReturnT:\n        self.begin()\n    \n        retry_state = RetryCallState(retry_object=self, fn=fn, args=args, kwargs=kwargs)\n        while True:\n            do = self.iter(retry_state=retry_state)\n            if isinstance(do, DoAttempt):\n                try:\n>                   result = fn(*args, **kwargs)\n\n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/tenacity/__init__.py:382: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nmypy/lib/llm/core/helper.py:83: in chat\n    response = self._client.chat.completions.create(\n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/openai/_utils/_utils.py:277: in wrapper\n    return func(*args, **kwargs)\n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/openai/resources/chat/completions.py:581: in create\n    return self._post(\n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/openai/_base_client.py:1232: in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/openai/_base_client.py:921: in request\n    return self._request(\n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/openai/_base_client.py:997: in _request\n    return self._retry_request(\n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/openai/_base_client.py:1045: in _retry_request\n    return self._request(\n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/openai/_base_client.py:997: in _request\n    return self._retry_request(\n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/openai/_base_client.py:1045: in _retry_request\n    return self._request(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <openai.OpenAI object at 0x7fb5933366a0>\n\n    def _request(\n        self,\n        *,\n        cast_to: Type[ResponseT],\n        options: FinalRequestOptions,\n        remaining_retries: int | None,\n        stream: bool,\n        stream_cls: type[_StreamT] | None,\n    ) -> ResponseT | _StreamT:\n        cast_to = self._maybe_override_cast_to(cast_to, options)\n        self._prepare_options(options)\n    \n        retries = self._remaining_retries(remaining_retries, options)\n        request = self._build_request(options)\n        self._prepare_request(request)\n    \n        kwargs: HttpxSendArgs = {}\n        if self.custom_auth is not None:\n            kwargs[\"auth\"] = self.custom_auth\n    \n        try:\n            response = self._client.send(\n                request,\n                stream=stream or self._should_stream_response_body(request=request),\n                **kwargs,\n            )\n        except httpx.TimeoutException as err:\n            log.debug(\"Encountered httpx.TimeoutException\", exc_info=True)\n    \n            if retries > 0:\n                return self._retry_request(\n                    options,\n                    cast_to,\n                    retries,\n                    stream=stream,\n                    stream_cls=stream_cls,\n                    response_headers=None,\n                )\n    \n            log.debug(\"Raising timeout error\")\n            raise APITimeoutError(request=request) from err\n        except Exception as err:\n            log.debug(\"Encountered Exception\", exc_info=True)\n    \n            if retries > 0:\n                return self._retry_request(\n                    options,\n                    cast_to,\n                    retries,\n                    stream=stream,\n                    stream_cls=stream_cls,\n                    response_headers=None,\n                )\n    \n            log.debug(\"Raising connection error\")\n            raise APIConnectionError(request=request) from err\n    \n        log.debug(\n            'HTTP Request: %s %s \"%i %s\"', request.method, request.url, response.status_code, response.reason_phrase\n        )\n    \n        try:\n            response.raise_for_status()\n        except httpx.HTTPStatusError as err:  # thrown on 4xx and 5xx status code\n            log.debug(\"Encountered httpx.HTTPStatusError\", exc_info=True)\n    \n            if retries > 0 and self._should_retry(err.response):\n                err.response.close()\n                return self._retry_request(\n                    options,\n                    cast_to,\n                    retries,\n                    err.response.headers,\n                    stream=stream,\n                    stream_cls=stream_cls,\n                )\n    \n            # If the response is streamed then we need to explicitly read the response\n            # to completion before attempting to access the response text.\n            if not err.response.is_closed:\n                err.response.read()\n    \n            log.debug(\"Re-raising status error\")\n>           raise self._make_status_error_from_response(err.response) from None\nE           openai.RateLimitError: Error code: 429 - {'error': {'message': 'The engine is currently overloaded, please try again later', 'type': 'engine_overloaded_error'}}\n\n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/openai/_base_client.py:1012: RateLimitError\n\nThe above exception was the direct cause of the following exception:\n\n    def test_xiaohongshu_title():\n        api = KimiHelper()\n        api.ask_helper.add_ask_message(\n            message=Xiaohongshu.XIAOHONGSHU_POST,\n            role=api.ask_helper.ROLE_SYSTEM)\n>       result = api.chat()\n\nmypy/tests/lib/llm/kimi/test_kimi.py:57: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/tenacity/__init__.py:289: in wrapped_f\n    return self(f, *args, **kw)\n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/tenacity/__init__.py:379: in __call__\n    do = self.iter(retry_state=retry_state)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <Retrying object at 0x7fb58363a6a0 (stop=<tenacity.stop.stop_after_attempt object at 0x7fb583631550>, wait=<tenacity.w...0x7fb583622b50>, before=<function before_nothing at 0x7fb5855b2ee0>, after=<function after_nothing at 0x7fb5855b91f0>)>\nretry_state = <RetryCallState 140417835979584: attempt #5; slept for 36.0; last result: failed (RateLimitError Error code: 429 - {'error': {'message': 'The engine is currently overloaded, please try again later', 'type': 'engine_overloaded_error'}})>\n\n    def iter(self, retry_state: \"RetryCallState\") -> t.Union[DoAttempt, DoSleep, t.Any]:  # noqa\n        fut = retry_state.outcome\n        if fut is None:\n            if self.before is not None:\n                self.before(retry_state)\n            return DoAttempt()\n    \n        is_explicit_retry = fut.failed and isinstance(fut.exception(), TryAgain)\n        if not (is_explicit_retry or self.retry(retry_state)):\n            return fut.result()\n    \n        if self.after is not None:\n            self.after(retry_state)\n    \n        self.statistics[\"delay_since_first_attempt\"] = retry_state.seconds_since_start\n        if self.stop(retry_state):\n            if self.retry_error_callback:\n                return self.retry_error_callback(retry_state)\n            retry_exc = self.retry_error_cls(fut)\n            if self.reraise:\n                raise retry_exc.reraise()\n>           raise retry_exc from fut.exception()\nE           tenacity.RetryError: RetryError[<Future at 0x7fb592e4f790 state=finished raised RateLimitError>]\n\n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/tenacity/__init__.py:326: RetryError","flaky":false,"newFailed":false,"newBroken":false,"newPassed":false,"retriesCount":0,"retriesStatusChange":false,"beforeStages":[{"name":"event_loop_policy","time":{"start":1713491339643,"stop":1713491339643,"duration":0},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"stepsCount":0,"attachmentsCount":0,"hasContent":false,"attachmentStep":false}],"testStage":{"status":"broken","statusMessage":"tenacity.RetryError: RetryError[<Future at 0x7fb592e4f790 state=finished raised RateLimitError>]","statusTrace":"self = <Retrying object at 0x7fb58363a6a0 (stop=<tenacity.stop.stop_after_attempt object at 0x7fb583631550>, wait=<tenacity.w...0x7fb583622b50>, before=<function before_nothing at 0x7fb5855b2ee0>, after=<function after_nothing at 0x7fb5855b91f0>)>\nfn = <function OpenAIBaseHelper.chat at 0x7fb583636310>\nargs = (<mypy.lib.llm.kimi.helper.KimiHelper object at 0x7fb5933230d0>,)\nkwargs = {}\nretry_state = <RetryCallState 140417835979584: attempt #5; slept for 36.0; last result: failed (RateLimitError Error code: 429 - {'error': {'message': 'The engine is currently overloaded, please try again later', 'type': 'engine_overloaded_error'}})>\ndo = <tenacity.DoAttempt object at 0x7fb592e4fac0>\n\n    def __call__(\n        self,\n        fn: t.Callable[..., WrappedFnReturnT],\n        *args: t.Any,\n        **kwargs: t.Any,\n    ) -> WrappedFnReturnT:\n        self.begin()\n    \n        retry_state = RetryCallState(retry_object=self, fn=fn, args=args, kwargs=kwargs)\n        while True:\n            do = self.iter(retry_state=retry_state)\n            if isinstance(do, DoAttempt):\n                try:\n>                   result = fn(*args, **kwargs)\n\n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/tenacity/__init__.py:382: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nmypy/lib/llm/core/helper.py:83: in chat\n    response = self._client.chat.completions.create(\n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/openai/_utils/_utils.py:277: in wrapper\n    return func(*args, **kwargs)\n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/openai/resources/chat/completions.py:581: in create\n    return self._post(\n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/openai/_base_client.py:1232: in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/openai/_base_client.py:921: in request\n    return self._request(\n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/openai/_base_client.py:997: in _request\n    return self._retry_request(\n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/openai/_base_client.py:1045: in _retry_request\n    return self._request(\n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/openai/_base_client.py:997: in _request\n    return self._retry_request(\n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/openai/_base_client.py:1045: in _retry_request\n    return self._request(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <openai.OpenAI object at 0x7fb5933366a0>\n\n    def _request(\n        self,\n        *,\n        cast_to: Type[ResponseT],\n        options: FinalRequestOptions,\n        remaining_retries: int | None,\n        stream: bool,\n        stream_cls: type[_StreamT] | None,\n    ) -> ResponseT | _StreamT:\n        cast_to = self._maybe_override_cast_to(cast_to, options)\n        self._prepare_options(options)\n    \n        retries = self._remaining_retries(remaining_retries, options)\n        request = self._build_request(options)\n        self._prepare_request(request)\n    \n        kwargs: HttpxSendArgs = {}\n        if self.custom_auth is not None:\n            kwargs[\"auth\"] = self.custom_auth\n    \n        try:\n            response = self._client.send(\n                request,\n                stream=stream or self._should_stream_response_body(request=request),\n                **kwargs,\n            )\n        except httpx.TimeoutException as err:\n            log.debug(\"Encountered httpx.TimeoutException\", exc_info=True)\n    \n            if retries > 0:\n                return self._retry_request(\n                    options,\n                    cast_to,\n                    retries,\n                    stream=stream,\n                    stream_cls=stream_cls,\n                    response_headers=None,\n                )\n    \n            log.debug(\"Raising timeout error\")\n            raise APITimeoutError(request=request) from err\n        except Exception as err:\n            log.debug(\"Encountered Exception\", exc_info=True)\n    \n            if retries > 0:\n                return self._retry_request(\n                    options,\n                    cast_to,\n                    retries,\n                    stream=stream,\n                    stream_cls=stream_cls,\n                    response_headers=None,\n                )\n    \n            log.debug(\"Raising connection error\")\n            raise APIConnectionError(request=request) from err\n    \n        log.debug(\n            'HTTP Request: %s %s \"%i %s\"', request.method, request.url, response.status_code, response.reason_phrase\n        )\n    \n        try:\n            response.raise_for_status()\n        except httpx.HTTPStatusError as err:  # thrown on 4xx and 5xx status code\n            log.debug(\"Encountered httpx.HTTPStatusError\", exc_info=True)\n    \n            if retries > 0 and self._should_retry(err.response):\n                err.response.close()\n                return self._retry_request(\n                    options,\n                    cast_to,\n                    retries,\n                    err.response.headers,\n                    stream=stream,\n                    stream_cls=stream_cls,\n                )\n    \n            # If the response is streamed then we need to explicitly read the response\n            # to completion before attempting to access the response text.\n            if not err.response.is_closed:\n                err.response.read()\n    \n            log.debug(\"Re-raising status error\")\n>           raise self._make_status_error_from_response(err.response) from None\nE           openai.RateLimitError: Error code: 429 - {'error': {'message': 'The engine is currently overloaded, please try again later', 'type': 'engine_overloaded_error'}}\n\n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/openai/_base_client.py:1012: RateLimitError\n\nThe above exception was the direct cause of the following exception:\n\n    def test_xiaohongshu_title():\n        api = KimiHelper()\n        api.ask_helper.add_ask_message(\n            message=Xiaohongshu.XIAOHONGSHU_POST,\n            role=api.ask_helper.ROLE_SYSTEM)\n>       result = api.chat()\n\nmypy/tests/lib/llm/kimi/test_kimi.py:57: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/tenacity/__init__.py:289: in wrapped_f\n    return self(f, *args, **kw)\n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/tenacity/__init__.py:379: in __call__\n    do = self.iter(retry_state=retry_state)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <Retrying object at 0x7fb58363a6a0 (stop=<tenacity.stop.stop_after_attempt object at 0x7fb583631550>, wait=<tenacity.w...0x7fb583622b50>, before=<function before_nothing at 0x7fb5855b2ee0>, after=<function after_nothing at 0x7fb5855b91f0>)>\nretry_state = <RetryCallState 140417835979584: attempt #5; slept for 36.0; last result: failed (RateLimitError Error code: 429 - {'error': {'message': 'The engine is currently overloaded, please try again later', 'type': 'engine_overloaded_error'}})>\n\n    def iter(self, retry_state: \"RetryCallState\") -> t.Union[DoAttempt, DoSleep, t.Any]:  # noqa\n        fut = retry_state.outcome\n        if fut is None:\n            if self.before is not None:\n                self.before(retry_state)\n            return DoAttempt()\n    \n        is_explicit_retry = fut.failed and isinstance(fut.exception(), TryAgain)\n        if not (is_explicit_retry or self.retry(retry_state)):\n            return fut.result()\n    \n        if self.after is not None:\n            self.after(retry_state)\n    \n        self.statistics[\"delay_since_first_attempt\"] = retry_state.seconds_since_start\n        if self.stop(retry_state):\n            if self.retry_error_callback:\n                return self.retry_error_callback(retry_state)\n            retry_exc = self.retry_error_cls(fut)\n            if self.reraise:\n                raise retry_exc.reraise()\n>           raise retry_exc from fut.exception()\nE           tenacity.RetryError: RetryError[<Future at 0x7fb592e4f790 state=finished raised RateLimitError>]\n\n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/tenacity/__init__.py:326: RetryError","steps":[],"attachments":[{"uid":"cbed15e46d059b5","name":"log","source":"cbed15e46d059b5.txt","type":"text/plain","size":1699}],"parameters":[],"shouldDisplayMessage":true,"stepsCount":0,"attachmentsCount":1,"hasContent":true,"attachmentStep":false},"afterStages":[],"labels":[{"name":"parentSuite","value":"lib.llm.kimi"},{"name":"suite","value":"test_kimi"},{"name":"host","value":"fv-az799-397"},{"name":"thread","value":"7152-MainThread"},{"name":"framework","value":"pytest"},{"name":"language","value":"cpython3"},{"name":"package","value":"lib.llm.kimi.test_kimi"},{"name":"resultFormat","value":"allure2"}],"parameters":[],"links":[],"hidden":false,"retry":false,"extra":{"severity":"normal","retries":[],"categories":[{"name":"Test defects","matchedStatuses":[],"flaky":false}],"tags":[]},"source":"661c2ff54a56dcb2.json","parameterValues":[]}