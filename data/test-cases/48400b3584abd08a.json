{"uid":"48400b3584abd08a","name":"test_openai","fullName":"lib.llm.openai.test_openai#test_openai","historyId":"bec48a14991ea927305301f48510589c","time":{"start":1713456968750,"stop":1713456971781,"duration":3031},"status":"broken","statusMessage":"Exception: 未输入问题","statusTrace":"def test_openai():\n        api = OpenAIHelper()\n        prompt = '明明是太阳晒我，为什么说我晒太阳'\n>       result = api.chat(prompt)\n\nmypy/tests/lib/llm/openai/test_openai.py:7: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/tenacity/__init__.py:289: in wrapped_f\n    return self(f, *args, **kw)\n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/tenacity/__init__.py:379: in __call__\n    do = self.iter(retry_state=retry_state)\n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/tenacity/__init__.py:314: in iter\n    return fut.result()\n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/concurrent/futures/_base.py:437: in result\n    return self.__get_result()\n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/concurrent/futures/_base.py:389: in __get_result\n    raise self._exception\n/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/tenacity/__init__.py:382: in __call__\n    result = fn(*args, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <mypy.lib.llm.openai.helper.OpenAIHelper object at 0x7ff792dbae80>\nuse_stream = '明明是太阳晒我，为什么说我晒太阳'\n\n    @retry(retry=retry_if_exception_type(RateLimitError),\n           stop=stop_after_attempt(CHAT_ATTEMPTS),\n           wait=wait_exponential(multiplier=CHAT_ERR_INTERVAL, max=CHAT_ERR_INTERVAL * CHAT_ATTEMPTS),\n           before_sleep=before_sleep_log(LOG, logging.WARNING))\n    def chat(self, use_stream=False) -> Tuple[str, str]:\n        time.sleep(random.randint(1, 3))\n        if not self.ask_helper.ask_messages:\n>           raise Exception('未输入问题')\nE           Exception: 未输入问题\n\nmypy/lib/llm/core/helper.py:81: Exception","flaky":false,"newFailed":false,"newBroken":false,"newPassed":false,"retriesCount":0,"retriesStatusChange":false,"beforeStages":[{"name":"event_loop_policy","time":{"start":1713454878019,"stop":1713454878019,"duration":0},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"stepsCount":0,"attachmentsCount":0,"hasContent":false,"attachmentStep":false}],"afterStages":[],"labels":[{"name":"parentSuite","value":"lib.llm.openai"},{"name":"suite","value":"test_openai"},{"name":"host","value":"fv-az1668-341"},{"name":"thread","value":"7212-MainThread"},{"name":"framework","value":"pytest"},{"name":"language","value":"cpython3"},{"name":"package","value":"lib.llm.openai.test_openai"},{"name":"resultFormat","value":"allure2"}],"parameters":[],"links":[],"hidden":false,"retry":false,"extra":{"severity":"normal","retries":[],"categories":[{"name":"Test defects","matchedStatuses":[],"flaky":false}],"tags":[]},"source":"48400b3584abd08a.json","parameterValues":[]}