- [参考资料](#参考资料)
- [★ 性能优化](#-性能优化)
  - [调优策略](#调优策略)
  - [MySQL 占用 CPU 超过 100% 怎么办](#mysql-占用-cpu-超过-100-怎么办)
  - [SQL 优化](#sql-优化)
    - [`insert` 优化](#insert-优化)
    - [`group by` 优化](#group-by-优化)
    - [`order by` 优化](#order-by-优化)
    - [`limit` 优化](#limit-优化)
    - [`in` 优化](#in-优化)
    - [`where` 优化](#where-优化)
  - [慢查询优化](#慢查询优化)
    - [explain 查看 SQL 执行计划](#explain-查看-sql-执行计划)
    - [`explain` 指标](#explain-指标)
    - [慢查询优化怎么做](#慢查询优化怎么做)
  - [数据库设计优化](#数据库设计优化)
    - [大量请求都是写数据，如何存储、存储数据太多，怎么处理](#大量请求都是写数据如何存储存储数据太多怎么处理)
    - [大表数据查询怎么优化](#大表数据查询怎么优化)
    - [数据表损坏的修复方式有哪些](#数据表损坏的修复方式有哪些)
    - [什么情况下需要去优化数据库](#什么情况下需要去优化数据库)
    - [如何更好地设计数据库](#如何更好地设计数据库)
- [其他](#其他)
  - [查询时，尽量指定查询的字段名](#查询时尽量指定查询的字段名)
  - [超大分页怎么处理](#超大分页怎么处理)
  - [监控指标](#监控指标)
  - [一条 Sql 语句查询偶尔慢会是什么原因](#一条-sql-语句查询偶尔慢会是什么原因)
  - [删除表数据后表的大小为什么没有变动](#删除表数据后表的大小为什么没有变动)
  - [为什么不要使用长事务](#为什么不要使用长事务)

# 参考资料

# ★ 性能优化

- [42 张图带你撸完 MySQL 优化](https://mp.weixin.qq.com/s/xXk5U3QF4k41lznkVewEeQ)

- [是什么影响了 MySQL 的性能](https://mp.weixin.qq.com/s/8WyoOmmi0ANcOTtq0i1hDQ)

- [常见 Mysql 的慢查询优化方式](https://blog.csdn.net/qq_35571554/article/details/82800463)

- [大并发 mysql 连接，time_wait 积累导致端口耗尽](https://blog.csdn.net/yuberhu/article/details/78972791)

## 调优策略

![alt](https://mmbiz.qpic.cn/mmbiz_jpg/tibrg3AoIJTtyNLZI14u9bf9jdcVFX7icZUib3hhCvWTTY8eWc4zIRxf4DaUS9Dxkaico2JeUL21C6MNnrgqSyQoIA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

- [抛开复杂的架构设计，MySQL 优化思想基本都在这了](https://mp.weixin.qq.com/s?__biz=MzI1OTcyODg1NQ==&mid=2247489220&idx=4&sn=078dbae2f13a3e8072bab29918478370&source=41#wechat_redirect)

- SQL 语句及索引的优化

  - 尽量不使用 `select *`，而是只查询需要的字段

  - 尽量避免全表扫描

  - 正确使用索引，避免在索引上进行计算（见 什么情况下设置了索引但无法使用 ）

- 数据库表结构的优化

  表设计尽量符合`三范式`

- 系统配置的优化

  MySQL 集群、负债均衡、读写分离、分库分表

- 硬件的优化

  加大内存、CPU、磁盘

- 缓存系统

  `redis 缓存`

## MySQL 占用 CPU 超过 100% 怎么办

- 打开慢查询日志，然后 cat 这个日志，检查哪里有问题

- `show full processlist;` 查看正在执行的 `sql` 语句

- 定位到语句后，再进行 SQL 优化、加索引，不要大范围查询等常规优化手段

## SQL 优化

- 对于查询尽量走索引

- 应该尽量避免全局扫描。如：`in、not in、like、where` 中使用 `or`、`where`中使用参数、`where`中使用`!=`和`<>`

- 行锁一定要命中索引，避免发生死锁

### `insert` 优化

> 批量插入、`insert delayed`

- 如果向同一张表插入多条数据的话，`最好一次性插入`，这样可以减少数据库建立连接 -> 断开连接的时间

- 向不同的表插入多条数据，可以使用 `insert delayed` 语句提高执行效率

  - `INSERT DELAYED INTO`，是客户端提交数据给 MySQL，MySQL 返回 OK 状态给客户端。而这是并不是已经将数据插入表，而是存储在内存里面等待排队。当 mysql 有空余时，再插入。

  - 好处是，提高插入的速度，客户端不需要等待太长时间

  - 坏处是，不能返回自动递增的 ID，以及系统崩溃时，MySQL 还没有来得及插入数据的话，这些数据将会丢失

### `group by` 优化

[`grou by` 优化详解](https://mp.weixin.qq.com/s/wUltusDRdbeJZ0Knnz8ZIw)

在使用分组和排序的场景下，如果先进行 Group By 再进行 Order By 的话，可以指定 `order by null` 禁止排序，因为 order by null 可以避免 filesort ，filesort 往往很耗费时间

```sql
select id, sum(moneys) from sales group by id order by null;
```

### `order by` 优化

explain 查看执行计划时，经常可以看到 `Extra` 列出现了 `filesort`，这是一种文件排序，这种排序方式比较慢，需要进行优化

- 优化方式就是创建索引，然后我们使用`where 字段和 order by 相同的顺序进行查询`（否则不会走索引）

  ```sql
  create index idx_age on test_tb(age);

  select id from test_tb a where a.age > 11 order by age;
  ```

### `limit` 优化

**问题描述**

MySQL 有 `limit 20000, 10` 的限制，是因为 `limit 20000, 10; -- 丢弃前面的 20000 条，取后面的 50 条` 后，如果只要取 10 条数据，就会丢弃前面的两万数据，导致效率低

**解决方案**

- `限制分页的数量`，业务上有没有必要查这么后的分页啦。因为绝大多数用户都不会往后翻太多页。

- `需要 where 【索引】，再根据需要的字段条件去返回`

  ```sql
  -- where 用到索引
  select id, name from employee where id > 1000000 limit 10;

  -- order by 会用到索引
  select id, name from employee order by id limit 1000000, 10;

  ```

- 如果只需要一条数据的情况下，推荐使用 `limit 1`，这样会使执行计划中的 type 变为 `const`

### `in` 优化

[MySQL 查询条件中 in 不一定用到索引](https://segmentfault.com/a/1190000019804419)，MySQL 优化器会选出自认为的最优解。

- [`in` 和 `exist` 的区别](https://mp.weixin.qq.com/s/IYfUDr4bsGyLOHIleOLPMw)

  ```sql
  -- in 是在内存里遍历比较，而 exists 需要查询数据库
  -- 当 B 表数据量较大时，【exists 效率优于 in】

  select * from A where id in (select id from B);

  select * from A where exists (select 1 from B where A.id = B.id);

  ```

- MySQL 中对 IN 做了相应的优化，MySQL 会将全部的常量存储在一个`数组里面，如果数值较多，产生的消耗也会变大`

  ```sql
  select name from dual where num in(4, 5, 6)
  -- 像这种 SQL 语句的话，能用 between 使用就不要再使用 in 了
  ```

- `in` 不一定走索引

  ```sql
  explain select * from device where id in (xx1, .... xx20000);  --不走索引，

  explain select * from device where id in (xx1, .... xx3000);   --走索引，
  -- 两者耗时相差无几，这部分应该是 MySQL 自己进行了优化
  ```

### `where` 优化

[MySQL - RANGE 优化篇](http://blog.battcn.com/2018/01/03/mysql/mysql-range-optimization/)

[mysql range 优化](http://blog.battcn.com/2018/01/03/mysql/mysql-range-optimization/)

- 避免在 WHERE 字句中对字段进行 `NULL 判断`

- 避免在 WHERE 中使用 `!=` 或 `<、>` 操作符

- 不建议使用 `%` 前缀模糊查询，例如 `like "%name"` 或者 `like "%name%"`，这种查询会导致索引失效而进行全表扫描。但是可以使用 `LIKE "name%"`

- 避免在 where 中对字段进行表达式操作，比如 `select user_id,user_project from table_name where age*2=36` 就是一种表达式操作，建议改为 `select user_id,user_project from table_name where age=36/2`

- 建议在 where 子句中确定 column 的类型，避免 column 字段的类型和传入的参数类型不一致的时候发生的类型转换

## 慢查询优化

> 查询之后才会记录到慢查询日志里

```sql
-- 查看慢查询配置
show variables like '%slow%';

show global variables like 'slow_query_log';

-- 开启慢查询日志
set global slow_query_log = 'ON'
```

### explain 查看 SQL 执行计划

> 可以在查询的 sql 前面增加 `explain` 命令，以此可以查看到 sql 的执行计划。查看结果中的 `type` 列和 `extra` 列。

```sql
explain select * from posts where id = 10;
+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+--------+
| id | select_type | table | partitions | type  | possible_keys | key     | key_len | ref   | rows | filtered | Extra  |
+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+--------+
| 1  | SIMPLE      | posts | <null>     | const | PRIMARY       | PRIMARY | 4       | const | 1    | 100.0    | <null> |
+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+--------+

1 row in set
Time: 0.016s
```

### `explain` 指标

- [MySQL 中 explain 的 type 的解释以及常见索引失效的情况](https://blog.csdn.net/q957967519/article/details/89335064)

| 指标            | 含义                                                                                                                                             |
| --------------- | ------------------------------------------------------------------------------------------------------------------------------------------------ |
| `id`            | 表示语句执行的优先级，id 相同，从上到下，id 不同，高值到低值。                                                                                   |
| `type`          | 从好到坏，`NULL > system > const > eq_ref > ref > fulltext > ref_or_null > index_merge > unique_subquery > index_subquery > range > index > ALL` |
| `possible_keys` | 查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询实际使用                                                                           |
| `key`           | 表示语句实际用到的索引                                                                                                                           |
| `ref`           |                                                                                                                                                  |
| `row`           | 表示查询遍历了多少行                                                                                                                             |
| `extra`         | 如果 `extra` 列值为 `Using filesort` 和 `Using temproary`，则表示这条 sql 写得贼垃圾，赶紧优化                                                   |

- type 更确切的说是一种数据库引擎查找表的一种方式

  | type 类型 | 含义 |
  | --------- | ---- |
  | `all`     |      |
  | `index`   |      |
  | `range`   |      |
  | `ref`     |      |
  | `eq_ref`  |      |
  | `const`   |      |
  | `null`    |      |

  - 如果 `type` 列为 `index 和 all`的时候，表示 sql 走的全表扫描

  - 如果 `type` 列为 `index 或 ref`的时候，表示走了索引

  - 其中 `index` 走的是非重复值的索引，`ref` 的索引是存在重复值的。ref 会比 index 性能差一丢丢，但影响不大，可以不用再优化了

### 慢查询优化怎么做

```sql
-- 查看是否开启慢日志
show global variables like 'slow_query_log';

-- 开启慢查询日志
set global slow_query_log = 'ON'

-- 对日志中查询较慢的 `sql` 进行 `explain` 查看是否使用了索引。
explain select * from test_tb where id = 100;

-- 分析输出的结果，看这条查询语句有没有走索引
```

## 数据库设计优化

### 大量请求都是写数据，如何存储、存储数据太多，怎么处理

> 通过 `show status` 可以看出是读多还是写多

- 使用 InnoDB 存储引擎

- 分库分表

### 大表数据查询怎么优化

- 限定查询范围，尽量不要出现 `limit 1000000, 10` 这种跨越大结果集查询小结果集的语句

- 优化 shema、sql 语句+索引；

- 第二加缓存，memcached, redis；

- 主从复制，读写分离：主库负责写，从库负责读

- 垂直拆分，根据你模块的耦合度，将一个大的系统分为多个小的系统，也就是分布式系统；

- 水平切分，针对数据量大的表，这一步最麻烦，最能考验技术水平，要选择一个合理的 sharding key, 为了有好的查询效率，表结构也要改动，做一定的冗余，应用也要改，sql 中尽量带 sharding key，将数据定位到限定的表上去查，而不是扫描全部的表；

### 数据表损坏的修复方式有哪些

使用 myisamchk 来修复，具体步骤：

- 修复前将服务停止。

- 打开命令行方式，然后进入到的/bin 目录。

- 执行 myisamchk –recover 数据库所在路径/\*.MYI

- 使用 repair table 或者 OPTIMIZE table 命令来修复，`REPAIR TABLE table_name` 修复表 `OPTIMIZE TABLE table_name` 优化表 REPAIR TABLE 用于修复被破坏的表。 OPTIMIZE TABLE 用于回收闲置的数据库空间，当表上的数据行被删除时，所占据的磁盘空间并没有立即被回收，使用了 OPTIMIZE TABLE 命令后这些空间将被回收，并且对磁盘上的数据行进行重排（注意：是磁盘上，而非数据库）

### 什么情况下需要去优化数据库

> 优化原则：减少系统瓶颈，减少资源占用，增加系统的反应速度。

- 系统的吞吐量瓶颈往往出现在数据库的访问速度上

- 随着应用程序的运行，数据库的中的数据会越来越多，处理时间会相应变慢

- 数据是存放在磁盘上的，读写速度无法和内存相比

### 如何更好地设计数据库

> 需要考虑数据冗余、查询和更新的速度、字段的数据类型是否合理等多方面的内容

- 将字段很多的表分解成多个表

  - 对于字段较多的表，如果有些字段的使用频率很低，可以将这些字段分离出来形成新表。

  - 因为当一个表的数据量很大时，会由于使用频率低的字段的存在而变慢。

- 增加中间表

  - 对于需要经常联合查询的表，可以建立中间表以提高查询效率。

  - 通过建立中间表，将需要通过联合查询的数据插入到中间表中，然后将原来的联合查询改为对中间表的查询。

- 增加冗余字段

  - 设计数据表时应尽量遵循范式理论的规约，尽可能的减少冗余字段，让数据库设计看起来精致、优雅。但是，合理的加入冗余字段可以提高查询速度。

  - 表的规范化程度越高，表和表之间的关系越多，需要连接查询的情况也就越多，性能也就越差。

注意：冗余字段的值在一个表中修改了，就要想办法在其他表中更新，否则就会导致数据不一致的问题。

# 其他

## 查询时，尽量指定查询的字段名

在日常使用 `select` 查询时，尽量使用 `select column_name` 这种方式，避免直接 `select *`，这样增加很多不必要的消耗（cpu、io、内存、网络带宽）；而且查询效率比较低

## 超大分页怎么处理

> 解决超大分页, 其实主要是靠缓存, 可预测性的提前查到内容, 缓存至 redis 等 k-v 数据库中, 直接返回即可.

- 数据库层面,这也是我们主要集中关注的(虽然收效没那么大),类似于 `select * from table where age > 20 limit 1000000,10` 这种查询其实也是有可以优化的余地的. 这条语句需要 load 1000000 数据然后基本上全部丢弃,只取 10 条当然比较慢. 当时我们可以修改为 `select * from table where id in (select id from table where age > 20 limit 1000000,10).` 这样虽然也 load 了一百万的数据, 但是由于索引覆盖,要查询的所有字段都在索引中,所以速度会很快. 同时如果 ID 连续的好,我们还可以 `select * from table where id > 1000000 limit 10` ,效率也是不错的,优化的可能性有许多种,但是核心思想都一样,就是减少 load 的数据.

- 从需求的角度减少这种请求, 主要是不做类似的需求(直接跳转到几百万页之后的具体某一页.只允许逐页查看或者按照给定的路线走,这样可预测,可缓存)以及防止 ID 泄漏且连续被人恶意攻击.

## 监控指标

- 了解当前数据库读为主还是写为主

  - `show status` 可以看到每种语句执行次数

  ```sql
  Com_select  -- 执行 SELECT 操作的次数，一次查询会使结果 + 1
  Com_insert  -- 执行 INSERT 操作的次数，对于批量插入的 INSERT 操作，只累加一次
  Com_update  -- 执行 UPDATE 操作的次数
  Com_delete  -- 执行 DELETE 操作的次数

  Innodb_rows_read      -- 执行 SELECT 操作查询的行数
  Innodb_rows_inserted  -- 执行 INSERT 操作插入的行数
  Innodb_rows_updated   -- 执行 UPDATE 操作更新的行数
  Innodb_rows_deleted   -- 执行 DELETE 操作删除的行数

  Connections        -- 查询数据库的连接次数，不管是否连接成功都会算上
  Uptime             -- 服务器工作时间
  Slow_queries       -- 慢查询次数
  Threads_connected  -- 查看当前打开的连接数量
  ```

## 一条 Sql 语句查询偶尔慢会是什么原因

- 数据库在刷新脏页

  比如 「redolog 写满了」，「内存不够用了」释放内存如果是脏页也需要刷，mysql 「正常空闲状态刷脏页」

- 没有拿到锁

## 删除表数据后表的大小为什么没有变动

在使用 delete 删除数据时，其实对应的数据行并不是真正的删除，是「逻辑删除」，InnoDB 仅仅是将其「标记成可复用的状态」，所以表空间不会变小

## 为什么不要使用长事务

- 并发情况下，数据库「连接池容易被撑爆」

- `「容易造成大量的阻塞和锁超时」`

  长事务还占用锁资源，也可能拖垮整个库，

- 执行时间长，容易造成「主从延迟」

- 「回滚所需要的时间比较长」

  事务越长整个时间段内的事务也就越多

- 「undolog 日志越来越大」

  长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。
