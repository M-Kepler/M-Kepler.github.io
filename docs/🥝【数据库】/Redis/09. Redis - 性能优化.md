- [参考资料](#参考资料)
- [性能分析](#性能分析)
  - [监控指标](#监控指标)
  - [Redis 如果慢会在哪个环节](#redis-如果慢会在哪个环节)
  - [运行状态监控](#运行状态监控)
  - [慢查询](#慢查询)
- [性能优化](#性能优化)
  - [pipeline](#pipeline)
  - [`KEYS` 和 `SMEMBERS`](#keys-和-smembers)
  - [`keys` 和 `scan` 的对比](#keys-和-scan-的对比)
  - [`bigkey` 问题](#bigkey-问题)
    - [问题分析](#问题分析)
    - [问题解决](#问题解决)
  - [缓存集中过期问题](#缓存集中过期问题)
- [CPU 占用过高](#cpu-占用过高)
- [内存占用过高](#内存占用过高)
- [其他](#其他)

# 参考资料

- [使用 Redis，你必须知道的 21 个注意要点](https://segmentfault.com/a/1190000039695869)

- [详解 Redis 可视化图形监控界面 RedisLive](https://www.linuxprobe.com/redis-graphical-redislive.html)

- [redis-monitor](https://github.com/LittlePeng/redis-monitor)

- [redis 性能监控和排查](https://www.cnblogs.com/zhuyeshen/p/10950330.html)

- [redis 的一些性能测试，主要是 keys 和 smembers](https://blog.csdn.net/hcmony/article/details/78648368)

- [Linux 下 Redis 安装 + 集群 + 性能监控](https://blog.csdn.net/sisibf/article/details/80943551)

- [Redis Info 命令 - 获取 Redis 服务器的各种信息和统计数值](https://www.redis.net.cn/order/3676.html)

- [Redis 性能问题排查：slowlog 和排队延时](https://blog.csdn.net/luoqinglong850102/article/details/106065197)

- [Redis 越来越慢？常见延迟问题定位与分析](https://segmentfault.com/a/1190000025135291)

# 性能分析

## 监控指标

[Redis 有哪些监控指标](https://mp.weixin.qq.com/s/Qk1LvHPWfVSNc8Iq3Kpdtw)

## Redis 如果慢会在哪个环节

- [Redis 变慢了，如何快速排查](https://mp.weixin.qq.com/s/tF1TNMmHqR0glPwnKjzfKw)

- [万字长文| Redis 为什么变慢了？一文讲透如何排查 Redis 性能问题](https://mp.weixin.qq.com/s/iYCiaa53nXWugU5uTHjeSw)

- 使用复杂度高的命令

- 存储大 `big key`

  如果一个 `key` 写入的数据非常大，`Redis` 在分配内存时也会比较耗时。同样的，当删除这个 `key` 的数据时，释放内存也会耗时比较久

- `集中过期`

  是不是过期策略有问题啊

- 实例内存达到上限

- `fork`耗时严重

  开启持久化的情况下，比如开启 `RDB` 持久化

## 运行状态监控

- 缓存命中率

- [`QUS`](https://www.cnblogs.com/svan/p/7029577.html)

  > 采用单线程响应命令，对于高流量的场景，`如果执行命令的时间在 1ms 以上，那么 redis 最多可支撑OPS（每秒操作次数）不到 1000`，因此高 OPS 场景的 REDIS 建议

  ```sql
  127.0.0.1:633 > info stats
  -- instantaneous_ops_per_sec 实际上就是我们过去16个 100ms 周期内的平均 QPS 值
  ```

- [排查手段](https://www.Redis.net.cn/order/3676.html)

  ```sh
  # 慢查询日志队列中；队列默认保存最近产生的 128 个慢查询命令
  127.0.0.1:6379> slowlog get 10

  # 查看自服务启动以来命令执行的统计情况
  127.0.0.1:6379> info commandstats
  ```

- 自带的工具 `redis-cli -p 6379 monitor`

- 自带的性能评估工具 `redis-benchmark`

## 慢查询

[REDIS SLOWLOG(慢日志)](https://www.cnblogs.com/wiseblog/articles/13573193.html)

```log
raise response ResponseError: BUSY Redis is busy running a script. You can only call SCRIPT KILL or SHUTDOWN NOSAVE
```

- `slowlog` 命令执行时间（不包含被阻塞的时间）

  ```sql
  -- 查看慢查询配置
  127.0.0.1:6379> config get slowlog*
  slowlog-log-slower-than: 10000    -- 微秒（10ms）
  slowlog-max-len: 128

  -- 修改慢查询日志
  127.0.0.1:6379> config set slowlog-log-slower-than: 20000

  -- 获取慢查询日志
  127.0.0.1:6379> slowlog get [n]
  1) Slow log id: 0                                          -- 慢查询日志ID
     Start at: 1616512782                                    -- 命令开始执行时间戳
     Running time(ms): 18495                                 -- 命令执行耗时（18495 微秒）
     Command: 1) "EVALSHA"                                   -- 所执行的命令
              1) "a1ba158a87b39f68b9dd50039a5b2640e3fc18cd"  -- 脚本SHA值
              2) 1                                           -- 参数个数
              3) "app"                                       -- KEYS 参数
              4) "get_contchk_info:7abf57e893764e37a41845f"  -- ARGV 参数
     Client IP and port: 127.0.0.1:1358                      -- 连接客户端
     Client name:

    -- 对应命令
    127.0.0.1:6379> evalsha "a1ba158a87b39f68b9dd50039a5b2640e3fc18cd" 1 "app" "get_contchk_info:bd481d40359d45a2a9d3fe78a115e560"

  -- 导出慢查询日志
  redis-cli -p 6333 -a redis@sfdc slowlog get 1000000 > redis_slowquery.log
  ```

# 性能优化

`Redis` 性能瓶颈在于 **`网络IO 和 磁盘IO`** 而非 CPU，`【使用多线程能提升 IO 的效率】`，从而整体提高 Redis 的性能

## pipeline

- `Pipelining` 的局限性（重要！）

  - 鉴于 Pipepining 发送命令的特性，Redis 服务器是以队列来存储准备执行的命令，而队列是存放在有限的内存中的，所以不宜一次性发送过多的命令。如果需要大量的命令，可分批进行，效率不会相差太远滴，总好过内存溢出嘛

  - 由于 pipeline 的原理是收集需执行的命令，到最后才一次性执行。所以无法在中途立即查得数据的结果（需待 pipelining 完毕后才能查得结果），这样会使得无法立即查得数据进行条件判断（比如判断是非继续插入记录）。

  - pipeline 的目的是将一批命令打包到一个内部维护的 queue 里，然后建立 socket 与 server 交互，`这时候是只会发送一次命令，也就是只会交互一次，然后 queue 内的命令都执行完后会一起返回结果`，这样大大减少了通信的次数

## `KEYS` 和 `SMEMBERS`

[Redis 命令 keys 和 scan 的区别](https://cloud.tencent.com/developer/article/1440487)

慎用 `keys` 和 `smembers`

- `keys` 命令的弊端

  `KEYS` 通来在用来删除相关的 key 时使用，但这个命令有一个弊端，在 Redis 拥有数百万及以上的 key 的时候，会执行的比较慢；

  更为致命的是，这个命令会阻塞 Redis 多路复用的 IO 主线程，如果这个线程阻塞，在此执行之间其他的发送向 Redis 服务端的命令，都会阻塞，从而引发一系列级联反应，导致瞬间响应卡顿，从而引发超时等问题。

  所以应该在生产环境禁止用使用 KEYS 和类似的命令 SMEMBERS，这种时间复杂度为 O（N），且会阻塞主线程的命令，是非常危险的。

- `SCAN` 增量迭代

  同样是 O(N) 复杂度的 `SCAN` 命令，**支持通配查找**

  `SCAN` 命令或者其他的 scan，如： `SSCAN`，`HSCAN`，`ZSCAN`命令，可以不用阻塞主线程，并支持游标按批次迭代返回数据，所以是比较理想的选择。

  `KEYS` 相比 `SCAN` 命令优点是，KEYS 是一次返回，而 **`SCAN` 是需要迭代多次返回**。

  但是，使用 SMEMBERS 命令可以返回集合键当前包含的所有元素， 但是对于 SCAN 这类增量式迭代命令来说， 因为 `在对键进行增量式迭代的过程中，键可能会被修改`，所以增量式迭代命令只能对被返回的元素提供有限的保证

## `keys` 和 `scan` 的对比

```sh
127.0.0.1:6379> keys [pattern]
KEYS will hang redis server, use SCAN instead.
Do you want to proceed? (y/n): y
# 收到 redis 的一个警告，因为 redis 是单线程的，所以会等待这个 keys 指令执行完才继续
# keys 操作是遍历算法，复杂度是 O(n)，所以一次性返回符合条件的，如果数据量很大的话，会等待很久，而且 keys 没有 offset limit 这种分页参数

127.0.0.1:6379>SCAN [cursor] MATCH [pattern] COUNT 2
# 复杂度虽然也是 O (n)，但是它是通过游标分步进行的，不会阻塞线程；
# 提供 limit 参数，可以控制每次返回结果的最大条数
# 返回的结果可能会有重复，需要客户端去重复，这点非常重要
# 可以使用 COUNT 选项来指定每次扫描应该从结果集返回多少元素，避免全量返回
```

## `bigkey` 问题

[Redis 大 key（bigkey）问题的排查与解决方案](https://www.icode9.com/content-2-787185.html)

### 问题分析

**什么是 bigkey 问题**

指的是 key 对应的 `value` 很大（而不是说占用内存很大）。指 Redis 的字符串类型过大，非字符串类型元素过多

**有什么危害**

Redis 中的大 key 一直是重点需要优化的对象，big key 既占用比较多的内存，也可能占用比较多的网卡资源，造成 redis 阻塞

**如何发现 bigkeys**

```sh
# Redis 命令 --bigkeys 每 0.2s 扫描一次
redis-cli -p 6333 -a redis@sfdc --bigkeys -i 0.2

# 查看 serializedlength 属性即可知道 value 序列化后占用的字节数
## serializedlength 不代表真实的字节大小，它返回对象使用 RDB 编码序列化后的长度，值会偏小，但是对于排查 bigkey 有一定辅助作用，因为不是每种数据结构都有类似 strlen 这样的方法。

127.0.0.1:6379> debug object [key]

# 查看字符串类型 bigkey 占用的字节数
127.0.0.1:6379> strlen [key]
```

### 问题解决

![alt](https://mmbiz.qpic.cn/mmbiz_png/wAkAIFs11qZWr2tPdmSkEC0wJbuBTyIIbLr6esC0JyoUnyAO4GGblBVMcVXovuMffgicGVo4nsYlF5nU8wTb0Dw/640?wx_fmt=png)

**使用上的规范**

- `string` 减少字符串长度

- `list、hash、set、zset` 等减少成员数

**局部操作**

对于非字符串类型的 `bigkey`，不需要一次性把所有元素都取出来，比如用 hmget 和 range 取部分数据

**压缩和拆分 `bigkey`**

- 当 vaule 是 `string` 时，比较难拆分

  - 可以考虑使用`序列化、压缩算法将 key 的大小控制在合理范围内`，但是序列化和反序列化都会带来更多时间上的消耗

  - 当 value 是 string，压缩之后仍然是大 key，则需要进行拆分，一个大 key 分为不同的部分，记录每个部分的 key，使用 multiget 等操作实现事务读取

- 当 value 是 `list / set` 等集合类型时

  - 根据预估的数据规模来进行`分片`，不同的元素计算后分到不同的片。

- `> 4.0` 版本，可采用 `UNLINK` 代替 `DEL`，该命令可以把释放 key 内存的操作，放到后台线程中去执行，从而降低对 Redis 的影响

- `> 4.0` 版本，可开启 `lazy-free` 机制，在执行 `DEL` 命令时，释放内存也会放到后台线程中去执行

## 缓存集中过期问题

- 如果业务上，不得不把一批缓存都置为过期，那么可以 `增加一个随机时间`，把集中国企的时间打开，降低 Redis 清理 key 的压力

- `> 4.0` 版本，可以开启 `lazy-free`，把删除操作交给后台线程去执行

# CPU 占用过高

[排查 Redis 实例 CPU 使用率高的问题](https://help.aliyun.com/document_detail/200630.html)

- `cProfile` 看一下，或者 `strace` 看一下。如果发现时间大量消耗在 `socket` 上，那很有可能是 **在循环里频繁调用 Redis 命令**

# 内存占用过高

[排查 Redis 实例内存使用率高的问题](https://help.aliyun.com/document_detail/200631.html)

- `MEMORY STATS` 命令查询内存使用详情

- `MEMORY USAGE [KEY]` 命令查询指定 Key 消耗的内存（单位为字节）

- `MEMORY DOCTOR` 命令获取内存诊断建议。

# 其他

- 慎用的 Set 相关命令：

  - `SMEMBERS`：返回指定 Hash 中所有的 member，时间复杂度 O(N)

  - `SUNION / SUNIONSTORE`：计算多个 Set 的并集并返回 / 存储至另一个 Set 中，时间复杂度 O(N)，N 为参与计算的所有集合的总 member 数

  - `SINTER / SINTERSTORE`：计算多个 Set 的交集并返回 / 存储至另一个 Set 中，时间复杂度 O(N)，N 为参与计算的所有集合的总 member 数

  - `SDIFF / SDIFFSTORE`：计算 1 个 Set 与 1 或多个 Set 的差集并返回 / 存储至另一个 Set 中，时间复杂度 O(N)，N 为参与计算的所有集合的总 member 数
