- [参考资料](#参考资料)
- [负载均衡](#负载均衡)
  - [为什么要做负载均衡](#为什么要做负载均衡)
  - [负载均衡实现方式](#负载均衡实现方式)
  - [负载均衡策略](#负载均衡策略)
  - [一致性哈希算法](#一致性哈希算法)
    - [与固定取模哈希有什么区别](#与固定取模哈希有什么区别)
    - [数据倾斜和节点雪崩问题](#数据倾斜和节点雪崩问题)
    - [解决节点雪崩的风险](#解决节点雪崩的风险)
- [其他](#其他)

# 参考资料

# 负载均衡

## 为什么要做负载均衡

> [什么是负载均衡，为什么要做负载均衡](https://www.cnblogs.com/daiyacheng1991/p/11471393.html)

- 解决并发压力，提高应用处理性能（增加吞吐量，加强网络处理能力）

- 提供故障转移，实现高可用

- 通过添加或减少服务器数量，提供网站伸缩性（扩展性）

- 安全防护；（负载均衡设备上做一些过滤，黑白名单等处理）

## 负载均衡实现方式

- `软件负载均衡`

  - `Nginx`

  - `LVS（Linux virtual server）`

  - `HAProxy`

- `硬件负载均衡`

> - 按照类型来划分的话，还可以分成 DNS 负载均衡、硬件负载均衡、软件负载均衡。
> - 其中硬件负载均衡价格昂贵，性能最好，能达到百万级，软件负载均衡包括 Nginx、LVS 这种

- `DNS 负载`

  [一个域名如何解析到多个 IP 地址](https://www.cnblogs.com/xiaobaiskill/p/10045596.html)

  一般用于实现地理级别的负载均衡，不同地域的用户通过 DNS 的解析可以返回不同的 IP 地址，这种方式的负载均衡简单，但是扩展性太差，控制权在域名服务商

- `HTTP 重定向`

  通过修改 Http 响应头的 Location 达到负载均衡的目的，Http 的 302 重定向。这种方式对性能有影响，而且增加请求耗时。

- `反向代理`

  作用于应用层的模式，也被称作为七层负载均衡，比如常见的 Nginx，性能一般可以达到万级。这种方式部署简单，成本低，而且容易扩展。

- `IP`

  作用于网络层和传输层的模式，也被称作四层负载均衡，通过对数据包的 IP 地址和端口进行修改来达到负载均衡的效果。常见的有 LVS（Linux Virtual Server），通常性能可以支持 10 万级并发。

## 负载均衡策略

> 轮询、按权轮询、url、ip、系统负载

- `随机分配`

  通过随机数生成算法选取一个服务器，然后把连接发送给它。

- `轮询`

  - 每一次把来自用户的请求轮流分配给内部中的服务器，从 1 开始，直到 N(内部服务器个数)，然后重新开始循环。算法的优点是其简洁性，它无需记录当前所有连接的状态，所以它是一种无状态调度。

  - 缺点：不考虑每台服务器的处理能力

- `加权轮询`

  由于每台服务器的配置、安装的业务应用等不同，其处理能力会不一样。所以，我们根据服务器的不同处理能力，给每个服务器分配不同的权值，使其能够接受相应权值数的服务请求。

- `源地址哈希`

  源地址散列调度算法是一种静态映射算法，它通过一个散列（Hash）函数将一个源 IP 地址映射到一台服务器，若该服务器是可用的并且没有超负荷，将请求发送到该服务器，否则返回空。它采用的散列函数与目标地址散列调度算法的相同。它的算法流程与目标地址散列调度算法的基本相似，除了将请求的目标 IP 地址换成请求的源 IP 地址，所以这里不一个一个叙述。

- `目标地址哈希`

  目标地址散列调度算法也是针对目标 IP 地址的负载均衡，它是一种静态映射算法，通过一个散列（Hash）函数将一个目标 IP 地址映射到一台服务器。目标地址散列调度算法先根据请求的目标 IP 地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且未超载，将请求发送到该服务器，否则返回空。

- `一致性哈希`

- `Least-Connection（最少连接）`

  最少连接调度算法是把新的连接请求分配到当前连接数最小的服务器，最小连接调度是一种动态调度短算法，它通过服务器当前所活跃的连接数来估计服务器的负载均衡，调度器需要记录各个服务器已建立连接的数目，当一个请求被调度到某台服务器，其连接数加 1，当连接中止或超时，其连接数减一，在系统实现时，我们也引入当服务器的权值为 0 时，表示该服务器不可用而不被调度。

## 一致性哈希算法

[白话解析：一致性哈希算法 consistent hashing](https://www.zsythink.net/archives/1182/)

[一致性 HASH 算法原理总结](https://mp.weixin.qq.com/s?__biz=MjM5ODYwMjI2MA==&mid=2649769105&idx=1&sn=c68d5174bb243701d69edc80ef5c04ea&chksm=beccd7ea89bb5efcbd7866c77edd91f9d5a67090bae678a4f1b6f7204f12d75abb486ed5903a&scene=90&subscene=93&sessionid=1646907172&clicktime=1646907174&enterid=1646907174&ascene=56&devicetype=android-31&version=28001511&nettype=cmnet&abtest_cookie=AAACAA%3D%3D&lang=zh_CN&exportkey=A%2F0lLzVmqtemoPdDkwgEtVw%3D&pass_ticket=zdXh1w6Jv6eqJPVv8%2FmL9o2qqspIvDz6mljKJrev1KyhNl3IOc8Fqly4%2BxwM%2F1PT&wx_header=3)

[★ 图解一致性哈希算法，全网（小区局域网）最通俗易懂](https://segmentfault.com/a/1190000023467362)

- 一致性哈希算法在是一种特殊的哈希算法，`在移除或者添加一个服务器时，能够【尽可能小地改变】已存在的服务请求与处理请求服务器之间的映射关系`

- 一致性哈希解决了简单哈希算法在分布式哈希表中存在的 **`动态伸缩等问题`**（提升扩展能力、容错能力）

### 与固定取模哈希有什么区别

**普通取模哈希算法及其局限性**

伸缩性差，新增还是减少服务器节点都会导致导致了`哈希值的大面积【更新】`，哈希值的更新也是意味着`节点缓存数据的迁移`

```sh
# 哈希计算公式：key % 节点总数 = Hash节点下标

# 假设有 3 个服务器节点编号 [0 - 2]
# 6 个缓存键值对编号 [1 - 6]
# 则完成哈希映射之后，三个缓存数据映射情况如下
1 % 3 = 1
2 % 3 = 2
3 % 3 = 0
4 % 3 = 1
5 % 3 = 2
6 % 3 = 0

# 假设【新增】了 1 个服务器节点
# 由原来的 3 个服务节点变成 4 个节点编号 [0 - 3]
1 % 4 = 1
2 % 4 = 2
3 % 4 = 3
4 % 4 = 0
5 % 4 = 1
6 % 4 = 2
# 后面三个缓存 key ：4、5、6 对应的存储节点全部失效了
# 这就需要把这几个节点的缓存数据迁移到更新后的节点上 (费时费力)
# 也就是由原来的节点 [1, 2, 0] 迁移到节点 [0, 1, 2]

# 假设【删除】 1 个服务器节点，由最初的 3 个服务节点变成 2 个，节点编号 [0 - 1]
1 % 2 = 1
2 % 2 = 0
3 % 2 = 1
4 % 2 = 0
5 % 2 = 1
6 % 2 = 0
# 仅仅删除了一个服务节点，也导致了哈希值的【大面积更新】，哈希值的更新也是意味着节点缓存数据的迁移
```

**一致性哈希算法**

哈希函数计算方法不变，只不过是通过构建**环状的 Hash 空间**代替普通的线性 Hash 空间

- 选择一个足够大的 Hash 空间（一般是 `0 ~ 2^32`）构成一个哈希环

  ![alt](https://mmbiz.qpic.cn/mmbiz_png/ceNmtYOhbMSia2djw54AqTpZTiaWkEfw3vT7dCVtJ5daouo5c8TZDlKEc8RtPic6mENqiawUK9IBOuiajqb8UibN6OAA/640?wx_fmt=png)

- 对于缓存集群内的每个 `【存储服务器节点】计算 Hash 值`，可以用服务器的 IP 或 主机名计算得到哈希值，计算得到的哈希值就是服务 `节点在 Hash 环上的位置`，哈希后的结果**对 2^32 取模**，结果肯定是落在 `0 ~ 2^31` 中的某个点

  ![alt](https://mmbiz.qpic.cn/mmbiz_png/ceNmtYOhbMSia2djw54AqTpZTiaWkEfw3vmME5iaCgJooPaJA73Myhn9icOHRUM1xnvmkQG3pxCSEQCfryqXGONvicw/640?wx_fmt=png)

- 对需要 `【存储的数据】同样也计算一次哈希值`，计算之后的哈希`也映射到环上`，数据存储的位置是**沿顺时针的方向找到的环上的第一个节点**

  ![alt](https://mmbiz.qpic.cn/mmbiz_png/ceNmtYOhbMSia2djw54AqTpZTiaWkEfw3v34cbYFzWCwWKE3xLfmD8awIcI3gsWobFl4kcPd9FZVdeuPxyGweUdw/640?wx_fmt=png)

**增加节点**

当缓存服务集群要新增一个节点 node3 时，受影响的只有 key3 对应的数据 value3，此时只需把 value3 由原来的节点 node0 迁移到新增节点 node3 即可，其余节点存储的数据保持不动。

![alt](https://i.loli.net/2020/07/31/t6AiUkVOrv8yeXW.png)

**收缩节点**

假设 node2 节点宕机下线，则原来存储于 node2 的数据 value2 和 value5 ，只需按顺时针方向选择新的存储节点 node0 存放即可，不会对其他节点数据产生影响。一致性哈希能把节点宕机造成的影响控制在顺时针相邻节点之间，避免对整个集群造成影响。

![alt](https://i.loli.net/2020/07/31/CxWSKtjhkXNenly.png)

### 数据倾斜和节点雪崩问题

- `数据倾斜`

  当`服务节点聚集在一起时`，缓存数据的 key 哈希都映射到 node2 的顺时针方向，数据按顺时针寻找存储节点就导致全都存储到 node0 上去，给单个节点很大的压力

  ![alt](https://mmbiz.qpic.cn/mmbiz_png/ceNmtYOhbMSia2djw54AqTpZTiaWkEfw3vrkwzAkoLvaAc3e9QiaoA6SnUCxXl1rdCn1zKEWqTYViaicUbP0lOv6ic4w/640?wx_fmt=png)

- `节点雪崩`

  - 如果其中某个节点出现了问题，那该节点承载的数据就都压到下一个节点；下一个节点如果也承受不了那么大的压力，数据就会越滚越大，后面的节点就会全线崩溃

  - 数据倾斜导致所有缓存数据都打到 node0 上面，有可能会导致 node0 不堪重负被压垮了，node0 宕机，数据又都打到 node1 上面把 node1 也打垮了，node1 也被打趴传递给 node2，这时候故障就像像雪崩时滚雪球一样越滚越大。

  ![alt](https://mmbiz.qpic.cn/mmbiz_png/ceNmtYOhbMSia2djw54AqTpZTiaWkEfw3vpNiamicHmsO3pticZKKLL7Hn1aZNvWfJnysXPlOLn5mXGjuV9hymoicdww/640?wx_fmt=png)

### 解决节点雪崩的风险

设置`【虚拟节点】`，去分担环上面的流量压力，避免数据越滚越大；感觉和滑动窗口限流异曲同工，都是通过细分区间来解决问题

- 虚拟节点，就是对原来单一的物理节点在哈希环上虚拟出几个它的分身节点

- `打到虚拟节点上的数据实际上也是映射到分身对应的物理节点上`，这样，一个物理节点可以**通过虚拟节点的方式【均匀分散】在哈希环的各个部分**，解决了数据倾斜问题

  ![alt](https://mmbiz.qpic.cn/mmbiz_png/ceNmtYOhbMSia2djw54AqTpZTiaWkEfw3vy019BGkPerBOsXMv4NsjZTly3yp4y5NmibLm3gAIYvHo5douBGVmh0g/640?wx_fmt=png)

# 其他
