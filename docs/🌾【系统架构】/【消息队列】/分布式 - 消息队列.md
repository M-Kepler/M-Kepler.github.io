- [参考资料](#参考资料)
- [消息队列](#消息队列)
  - [方案选型](#方案选型)
    - [Redis](#redis)
    - [Kafka](#kafka)
  - [原理](#原理)
    - [为什么要用消息队列](#为什么要用消息队列)
    - [消息队列的缺点是什么](#消息队列的缺点是什么)
    - [引入消息队列如何做到高可用](#引入消息队列如何做到高可用)
    - [什么是接口幂等性](#什么是接口幂等性)
    - [什么是读扩散、写扩散](#什么是读扩散写扩散)
  - [常见问题](#常见问题)
    - [如何解决消息被【重复消费】问题](#如何解决消息被重复消费问题)
    - [如何解决消息【丢失】问题](#如何解决消息丢失问题)
    - [如何解决消息【顺序性】问题](#如何解决消息顺序性问题)
    - [如何确保数据【一致性】问题](#如何确保数据一致性问题)
    - [如何解决消息【积压】问题](#如何解决消息积压问题)
    - [如何处理消息【过期】问题](#如何处理消息过期问题)
    - [消息中间件如何做到高可用](#消息中间件如何做到高可用)
  - [其他](#其他)
    - [如何支持延时消费问题](#如何支持延时消费问题)

# 参考资料

- [★ 消息队列常问面试题](https://blog.csdn.net/weixin_39265427/article/details/107418735)

- [消息队列的那些事](https://mp.weixin.qq.com/s/V2I3kN43pgQiQPlygc2ObQ)

- [消息队列和 Zookeeper 面试题](https://www.iamshuaidi.com/1633.html)

- [★ 从演进式角度看消息队列](https://mp.weixin.qq.com/s/cZqUaIET2lCtr-SCFniIAg)

- [消息队列常见面试问题小集合](https://www.cnblogs.com/zz-ksw/p/12302431.html)

- [关于消息队列的使用](https://www.cnblogs.com/linjiqin/p/5720865.html)

# 消息队列

- 观察者模式（发布订阅） + 生产者消费者模式

- 当【不需要立即获得结果】，但是【并发量又需要控制】的时候，差不多就是需要使用消息队列的时候。

## 方案选型

### Redis

- Redis 的 list 可以用来做消息队列

  - `lpush` 从队列左边插入数据

  - `rpop` 从队列右边取出数据

这正好对应了我们队列抽象的 `push_front` 和 `pop_tail`，因此我们可以直接把 Redis 的 list 当成一个消息队列来使用。而且 Redis 本身对高并发做了很好的优化，内部数据结构经过了精心地设计和优化。所以从某种意义上讲，用 Redis 的 list 大概率比你自己重新实现一个 list 强很多。

但另一方面，使用 Redis list 作为消息队列也有一些不足，比如：

- `消息持久化`

  Redis 是内存数据库，虽然有 aof 和 rdb 两种机制进行持久化，但这只是辅助手段，这两种手段都是不可靠的。当 Redis 服务器宕机时一定会丢失一部分数据，这对于很多业务都是没法接受的。

- **热 key 性能问题**

  不论是用 codis 还是 twemproxy 这种集群方案，对某个队列的读写请求最终都会落到同一台 Redis 实例上，并且无法通过扩容来解决问题。如果对某个 list 的并发读写非常高，就产生了无法解决的热 key，严重可能导致系统崩溃。

- **没有确认机制**

  每当执行 rpop 消费一条数据，那条消息就被从 list 中永久删除了。如果消费者消费失败，这条消息也没法找回了。你可能说消费者可以在失败时把这条消息重新投递到进队列，但这太理想了，极端一点万一消费者进程直接崩了呢，比如被 kill -9，panic，coredump…

- **不支持多订阅者**

  一条消息只能被一个消费者消费，rpop 之后就没了。如果队列中存储的是应用的日志，对于同一条消息，监控系统需要消费它来进行可能的报警，BI 系统需要消费它来绘制报表，链路追踪需要消费它来绘制调用关系…… 这种场景 Redis list 就没办法支持了。

- **不支持二次消费**

  一条消息 rpop 之后就没了。如果消费者程序运行到一半发现代码有 bug，修复之后想从头再消费一次就不行了。

### Kafka

Kafka 一个最基本的架构认识：由多个 broker 组成，每个 broker 是一个节点；你创建一个 topic，这个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分数据。这就是天然的分布式消息队列，就是说一个 topic 的数据，是分散放在多个机器上的，每个机器就放一部分数据。

热 key 的本质问题是数据都集中在一台实例上，所以想办法把它分散到多个机器上就好了。为此，kafka 提出了 ==**partition**== 的概念。一个队列（Redis 中的 list），对应到 kafka 里叫 ==**topic**==

kafka 把一个 topic 拆成了多个 partition，每个 partition 可以分散到不同的机器上，这样就可以把单机的压力分散到多台机器上。因此 topic 在 kafka 中更多是一个逻辑上的概念，实际存储单元都是 partition。

其实 Redis 的 list 也能实现这种效果，不过这需要在业务代码中增加额外的逻辑。比如可以建立 n 个 list，key1, key2, ..., keyn，客户端每次往不同的 key 里 push，消费端也可以同时从 key1 到 keyn 这 n 个 list 中 rpop 消费数据，这就能达到 kafka 多 partition 的效果。所以你可以看到，partition 就是一个非常朴素的概念，用来把请求分散到多台机器。

Redis list 中另一个大问题是 rpop 会删除数据，所以 kafka 的解决办法也很简单，不删就行了嘛。kafka 用 游标 ==**cursor**== 解决这个问题。

## 原理

### 为什么要用消息队列

> `解耦、异步、削峰`

- `异步处理`

  ![alt](http://images2015.cnblogs.com/blog/270324/201607/270324-20160730141236169-1140938329.png)

  完成流程 A 后才能接着流程 B(发邮件)、流程 C(发短信)，正常要`等`全部完成才算整个业务完成；完成流程 A，就认为成功了，`写入消息队列`，后续 B、C 流程读取消息队列，知道 A 完成了，然后执行自己的流程

- `应用解耦`

  ![alt](http://images2015.cnblogs.com/blog/270324/201607/270324-20160730143228325-953675504.png)

  A 调用 B，如果 B 挂掉了，则 A 也就没返回，无法继续；就是一个系统或者一个模块，调用了多个系统或者模块，相互之间的调用很复杂，维护起来很麻烦。但是其实这个调用是`不需要直接同步调用`接口的，如果 MQ 给他异步化解耦也是可以的，你就需要去考虑在你的项目里是不是可以运用这个 MQ 去进行系统解耦 。 A 把消息写到消息队列就完事了，B 从消息队列中取消息进行处理

- `流量削锋`

  ![alt](http://images2015.cnblogs.com/blog/270324/201607/270324-20160730151710106-2043115158.png)

  如果一次有 `5000` 个请求同时过来，系统负载太高，无法及时处理，这时候可以先把这些请求放入到消息队列中，系统从消息队列取消息进行处理。`zmq` 的 `router-dealer` 模式就是这个样子，可以理解为增加了个 **缓存层**

- `日志处理`

  ![alt](http://images2015.cnblogs.com/blog/270324/201607/270324-20160730152810934-1818295010.png)

  日志采集系统采集日志后写入到消息队列，日志处理系统订阅并消费队列中的日志数据

### 消息队列的缺点是什么

> - 系统可用性降低(万一 MQ 挂了)
> - 系统稳定性降低(MQ 消息重发、丢失等)
> - 分布式一致性问题(需要分布式事务方案来保障)

- `系统可用性降低`

  本来系统间直接调用就好了，现在引入了消息队列，业务正常的前提是消息队列不能出现问题，否则数据都丢失了；而且消息队列崩了影响的是整个系统，而不是某几个模块。

- `系统复杂度变高`

  引入消息队列，要处理复杂多变的情况，比如消息重复消费、消息丢失、消息顺序性等问题都要解决

- `一致性问题`

  比如上面说到的解耦上的应用，A 业务系统把消息往消息队列一扔就管了（实际上是期望 B C D 系统都能拿到这条消息做处理），但实际上如果 B C 系统处理成功了，D 系统处理失败了，那 B C D 三个系统的数据就不一致了，或者说不好把控了。

### 引入消息队列如何做到高可用

> [引入消息队列之后，如何保证其高可用](https://blog.csdn.net/hanjungua8144/article/details/86238255)

- [消息队列集群](https://www.cnblogs.com/zdnscloud/p/14487693.html)

### 什么是接口幂等性

> - [接口的幂等性怎么设计](https://mp.weixin.qq.com/s/MopxNjZDM1MCLODxMCOy8w)
> - [高并发下如何保证接口的幂等性](https://mp.weixin.qq.com/s/TZrJvPvWNFgKyyHsJIQG6g)

用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而得到不一样的结果

- 插入前先查询

- 加悲观锁

  ```sql
  select * from user where id = 12 for update;  -- 加行锁
  ```

- 加乐观锁

- 加唯一索引

### 什么是读扩散、写扩散

> 就是消息是`推`还是`拉`的意思

- [读扩散和写扩散的理解](https://blog.csdn.net/aaa821/article/details/72550767)

- `写扩散`

  `主动把消息【推送】到订阅者的消息列表里`，这样订阅者就不用去我的 outbox 拉取消息 ，所以当我要是有很多订阅者时，我就要写很多次，这就是上面定义中说的写很重

- `读扩散`

  `主动去【拉取】被订阅者的消息`, 这样就不需要被订阅者主动写消息到我的消息列表里来，所以当我要是订阅了很多人时，我就要去读取这些人的所有新消息，所以就出现了读很重

- 又联想到了数据库中表之间的关系设计了, 两个表之间有关联关系，那这个关系该由谁来维护，同样可以用读扩散和写扩散的概念来思考，其实也可以说，表关系的维护设计，是写扩散和读扩散的具体实现

## 常见问题

### 如何解决消息被【重复消费】问题

本质上还是问使用消息队列如何保证【幂等性】，`重复消息产生的根本原因: 网络不可达`

> 搞个本地表，带唯一业务标记的，利用主键或者唯一性索引，每次处理业务，先校验一下就好啦。又或者用 Redis 缓存下业务标记，每次看下是否处理过了。

- 根据主键先查一下，如果这数据都有了，你就别插入了，update 一下

- 使用 `set` 命令写 `Redis`

- 全局唯一的 `id`

- 数据库唯一键

### 如何解决消息【丢失】问题

![alt](https://mmbiz.qpic.cn/mmbiz_png/PoF8jo1PmpyvQAZ3eSuN9XibLK4hDzyjZ8f2bfhS3xcKmA5DNC7J0fFOlf29B1L35fQYjljrPhPcJyzYnowRVLA/640?wx_fmt=png)

消息可能的情况是：生产者生产后发送消息过程丢失；MQ 本身丢失消息；消费者丢失消息

> 消息持久化，保存起来，并且增加 ACK 确认，消费后要告知消息队列

- 弄一张表记录发送出去的消息，消息被消费之后，修改标记为已确认

- 定时检查该表，如果一段时间后，消息还没有被消费，则认为消息丢失了，重新发送该消息

### 如何解决消息【顺序性】问题

感觉就像集群系统中如何保持 session 一致性一样，请求可能被多个消费者分别处理了

- 像做负载均衡那样，根据消息特征，确保同一组消息（比如同一个订单号的消息）每次都能路由到同一个队列

- 多个消费者队列中取得消息进行消费

- 加锁，确保单个 partition 是有序处理的

```
- Kafka 的全局有序消息，就是这种思想的体现: 就是生产者发消息时，1 个 Topic 只能对应 1 个 Partition，一个 Consumer，内部单线程消费。

- 但是这样吞吐量太低，一般保证消息局部有序即可。在发消息的时候指定 Partition Key，Kafka 对其进行 Hash 计算，根据计算结果决定放入哪个 Partition。这样 Partition Key 相同的消息会放在同一个 Partition。然后多消费者单线程消费指定的 Partition。
```

### 如何确保数据【一致性】问题

> 分布式事务

### 如何解决消息【积压】问题

> - 横向扩展：搞消息队列集群
> - 监控哪些消息比较频繁、消费又慢
> - 增加消费者数量，搞多进程、多线程（注意消息的顺序性）
> - 再开一个消息队列，进行业务分流

[消费者读取处理慢](https://blog.csdn.net/weixin_42537831/article/details/113372005)

- 消息积压的原因是什么

  - 生产者的生产速度与消费者的消费速度不匹配

  - 有可能是因为消息消费失败反复重试造成的

  - 也有可能就是消费者消费能力弱，渐渐地消息就积压了

- 因此我们需要先定位消费慢的原因，如果是 bug 则处理 bug ，如果是因为本身消费能力较弱，我们可以优化下消费逻辑，比如之前是一条一条消息消费处理的，这次我们批量处理，比如数据库的插入，一条一条插和批量插效率是不一样的。

- 假如逻辑我们已经都优化了，但还是慢，那就得考虑水平扩容了，增加 Topic 的队列数和消费者数量，注意队列数一定要增加，不然新增加的消费者是没东西消费的。一个 Topic 中，一个队列只会分配给一个消费者。

- 当然你消费者内部是单线程还是多线程消费那看具体场景。不过要注意上面提高的消息丢失的问题，如果你是将接受到的消息写入内存队列之后，然后就返回响应给 Broker，然后多线程向内存队列消费消息，假设此时消费者宕机了，内存队列里面还未消费的消息也就丢了。

### 如何处理消息【过期】问题

### 消息中间件如何做到高可用

## 其他

### 如何支持延时消费问题

> `[实现延时任务的 4 种实现方案.md]`

- Redis 的 zset 结构，把延时时间作为 score；通过 `zrange key start stop withscores` 读取出任务

- RocketMQ 是自带延时队列功能的
