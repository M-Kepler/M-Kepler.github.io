- [参考资料](#参考资料)
- [海量数据](#海量数据)
  - [一些概念](#一些概念)
  - [堆](#堆)
    - [适用场景](#适用场景)
    - [优缺点](#优缺点)
  - [哈希](#哈希)
    - [适用场景](#适用场景-1)
    - [优缺点](#优缺点-1)
  - [位图](#位图)
    - [优点](#优点)
    - [缺点](#缺点)
  - [字典树](#字典树)
  - [布隆过滤器](#布隆过滤器)
    - [适用场景](#适用场景-2)
      - [缓存系统](#缓存系统)
      - [判断某个元素是否在集合中](#判断某个元素是否在集合中)
    - [优缺点](#优缺点-2)
  - [MapReduce](#mapreduce)
- [应用](#应用)
  - [给定 a、b 两个文件，各存放 50 亿个 url，每个 url 各占 64 字节，内存限制是 4G，找出 a、b 文件共同的 url](#给定-ab-两个文件各存放-50-亿个-url每个-url-各占-64-字节内存限制是-4g找出-ab-文件共同的-url)
  - [4 亿个数，你只有 1G 内存，你怎么判断某个数已经出现](#4-亿个数你只有-1g-内存你怎么判断某个数已经出现)
  - [给 40 亿个不重复的无符号整型，没排过序。如何快速判断这个数存不存在](#给-40-亿个不重复的无符号整型没排过序如何快速判断这个数存不存在)
  - [数据库里存了很多 800 电话号码，数量特别大，以至于内存放不下，如何排序，时间比空间更重要？电话号码类似于 800-810-5555](#数据库里存了很多-800-电话号码数量特别大以至于内存放不下如何排序时间比空间更重要电话号码类似于-800-810-5555)
  - [五个文件每个文件一亿的数据，内存无法读取出来，请统计五亿号码不同的号码的计数](#五个文件每个文件一亿的数据内存无法读取出来请统计五亿号码不同的号码的计数)
  - [假设我们有 1 亿个整数，数据范围是从 1 到 10 亿，如何快速并且省内存地给这 1 亿个数据从小到大排序](#假设我们有-1-亿个整数数据范围是从-1-到-10-亿如何快速并且省内存地给这-1-亿个数据从小到大排序)
  - [一个文本文件，约一万行，每行一个词，统计出其中最频繁的 10 个词，给出思想及时间复杂度分析](#一个文本文件约一万行每行一个词统计出其中最频繁的-10-个词给出思想及时间复杂度分析)
  - [从两个文件各有 50 亿条数据的文件中找出相同的 URL](#从两个文件各有-50-亿条数据的文件中找出相同的-url)

# 参考资料

- [★ 大数据算法](https://www.cnblogs.com/xzwblog/p/7127362.html)

- [★ 海量数据处理 - 10 亿个数中找出最大的 10000 个数](https://blog.csdn.net/zyq522376829/article/details/47686867/)

- [亿万级数据处理的高效解决方案](https://zhuanlan.zhihu.com/p/90848602)

- [巧用 hash 表高效解决数据比对](https://mp.weixin.qq.com/s?__biz=MzI4NDMyNzA4NQ==&idx=1&mid=2247483816&sn=9c60561b82c016ed8be741260bc5b157)

- [海量数据处理面试题集锦\_结构之法 算法之道](https://blog.csdn.net/v_july_v/article/details/6685962)

- [面对千万级、亿级流量怎么处理？](https://www.cnblogs.com/ilovejaney/p/13893995.html)

- [★ 高效大数据开发之 bitmap 思想的应用](https://mp.weixin.qq.com/s/c5HDenoVde11IMmezj1v1Q)

- [海量数据处理之经典实例分析](https://segmentfault.com/a/1190000000510258)

# 海量数据

## 一些概念

- [吞吐量（TPS）、QPS、并发数、响应时间（RT）](https://www.cnblogs.com/data2value/p/6220859.html)

- `1G = 1073741824 Byte` 大概等于 10 亿字节

## 堆

### 适用场景

元素插入堆的时候，只要跟堆顶比较一下（因为堆顶是堆里面最小的了），如果比堆顶大才有资格进堆，否则不要

```cpp
priority_queue<int, vector<int>, greater<int>> pq;
```

### 优缺点

## 哈希

《哈希必知必会.md》

### 适用场景

> `Hash 取模，将大文件分解为多个小文件`，分治的思想

### 优缺点

## 位图

《位运算必知必会.md》

### 优点

- 节省内存，题目中给出的数据内存装不下的，都可以往位图考虑

### 缺点

数据最好是惆集数据 (不然空间浪费很大)；数据不可重复 (会将重复的数据覆盖掉)

- `数据碰撞`

  比如将字符串映射到位图的时候会有碰撞的问题，那就可以考虑用`布隆过滤器`来解决，其使用多个 Hash 函数来减少冲突的概率，比如`用位图进行排序`的一个条件就是不能产生碰撞

- `★ 数据稀疏`

  又比如要存入 (10, 8887983, 93452134) 这三个数据，我们需要建立一个 99999999 长度的 BitMap ，但是实际上只存了 3 个数据，这时候就有很大的空间浪费，碰到这种问题的话，可以通过引入 Roaring BitMap 来解决。

## 字典树

[[前缀树（字典树）]]

## 布隆过滤器

> 布隆过滤器 = `哈希 + 位图`

- [布隆过滤器你值得拥有的开发利器](https://segmentfault.com/a/1190000021136424)

![alt](https://mmbiz.qpic.cn/mmbiz_png/EoJib2tNvVtcjKW2LduuicLMU8Y4GugWGfdRfeOrib9PWhudv43WVuYwzAXqenWxp4zbCEoLUhX5hxpnIqJXqK3gg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

- 如果想要判断一个元素是不是在一个集合里，一般想到的是将所有元素保存起来，然后通过比较确定。链表，树、哈希表等数据结构都是这种思路，这些数据结构面对数据量特别大的时候显现的缺点：

  - 存储容量占比高，考虑到负载因子的存在，通常空间是不能被用满的

  - 当数据量特别大时，会占用大量的内存空间。如果存储了类似于 URL 这样的 key，那么内存消费太严重

  - 如果使用 hashmap，如果已有元素超过了总容量的一半之后，一般就需要考虑扩容了，因为元素多了之后哈希冲突就会增加，退化为链表存储的效率了

- 判断元素是否存在于集合中，一般想到的是将所有元素保存起来，然后通过比较确定。链表，树等等数据结构都是这种思路

- 但随着集合中元素的增加，我们需要的存储空间越来越大，检索速度也越来越慢。不过世界上还有一种叫作散列表（又叫哈希表，Hash table）的数据结构。它可以`通过哈希将元素映射成一个位阵列（Bit Array）中的一个点（与位图结合）`。这样一来，我们只要看看这个点是不是 1 就知道可以知道中有没有它了。这就是布隆过滤器的基本思想

- 核心思想就是利用`多个独立的 Hash 函数来解决冲突`，把哈希值映射到位图上，判断元素是否存在于集合中时，同样用这几个哈希函数取值并判断位图上是否`都为 1`，有一个不是，就表明这个元素不再集合中

  - 对值进行三次哈希计算，得到三个值 n1, n2, n3。

  - 把位数组中三个元素 arr[n1], arr[n2], arr[3] 置为 1

- 有可能产生误判

  > 布隆说不在，那肯定不在；实际不在的时候，布隆也有可能说在

  当插入的元素原来越多，位数组中被置为 1 的位置就越多，当一个不在布隆过滤器中的元素，经过哈希计算之后，得到的值在位数组中查询，有可能这些位置也都被置为 1。这样一个不存在布隆过滤器中的也有可能被误判成在布隆过滤器中。

### 适用场景

#### 缓存系统

增加一个 `bloom` 算法的服务，后端每插入一个 key 时，在这个服务中设置一次需要查询后端时，先判断 key 在后端是否存在，这样就能避免后端的压力

#### 判断某个元素是否在集合中

![alt](https://pic002.cnblogs.com/images/2012/274814/2012071317402283.png)

- 首先需要 k 个 hash 函数，每个函数可以把 key 散列成为 1 个整数

- 初始化时，需要一个长度为 n 比特的数组，每个比特位初始化为 0

- 某个 key 加入集合时，用 k 个 hash 函数计算出 k 个散列值，并把数组中对应的比特位置为 1

- 判断某个 key 是否在集合时，用 k 个 hash 函数计算出 k 个散列值，并查询数组中对应的比特位，如果`所有的比特位都是 1，认为在集合中`

### 优缺点

- 优点

  - 不需要存储 key，节省空间

  - 空间效率和查询时间远胜于一般算法

- 缺点

  - 算法判断 key 在集合中时，有一定的概率 key 其实不在集合中（有一定的误识别率）

    布隆过滤器 `有可能会出现错误判断，但不会漏掉判断`。也就是 Bloom Filter 判断元素不在集合，那肯定不在。

  - 无法删除

## MapReduce

[MapReduce 极简教程](https://mp.weixin.qq.com/s/nrjEEO2gB15tvZSDE9RvoQ)

- `MapReduce` 是一种编程模型，用于大规模数据集（大于 1TB）的并行运算。概念 `Map（映射）` 和 `Reduce（归约）`，是它们的主要思想

- 有点像是分布式一样，比如想要数出一摞牌中有多少张黑桃。直观方式是一张一张检查并且数出有多少张是黑桃；`MapReduce` 方法则是：给在座的所有玩家中分配这摞牌；让每个玩家数自己手中的牌有几张是黑桃，然后把这个数目汇报给你；你把所有玩家告诉你的数字加起来，得到最后的结论

- [ZMQ PUSH + PULL 模式](<https://zhuanlan.zhihu.com/p/80460493#1.3.%20Push-Pull(%E5%B9%B3%E8%A1%8C%E7%AE%A1%E9%81%93%E6%A8%A1%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%84%E7%90%86)>)

# 应用

- [★ 海量处理 TopK 问题](https://blog.csdn.net/zengxiaosen/article/details/54972733?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_title~default-1.control&spm=1001.2101.3001.4242)

## 给定 a、b 两个文件，各存放 50 亿个 url，每个 url 各占 64 字节，内存限制是 4G，找出 a、b 文件共同的 url

> 可估计每个文件的大小为 `5G×64=320G`，远远大于内存限制。所以不可能将其完全加载到内存中处理。考虑采取分而治之的方法

- [从两个文件 50 亿数据中找出相同的 URL](https://blog.csdn.net/qingdujun/article/details/82343756)

- 分治策略：通过 `Hash` 的方法，把 N 个大文件哈希为 10000 个小文件（可以使用字符串哈希函数 `BKDRHash`）

- 将小文件里的数据放入到`集合`中并取交集，得到的就是相同 URL 了

## 4 亿个数，你只有 1G 内存，你怎么判断某个数已经出现

- 位图法

  - int 的取值范围是`−2^31 - 2^31−1`, 我们可以连续申请 `2^32 bit = 2^30 byte = 1G`的内存, 这样，每个 bit 都可以对应一个 int 数字，将这 1G 内存初始化为 0

  - 接下来每次处理一个数字，就给它所对应的 bit 设为 1，查询时就只要看其对应的 bit 值，当然 0 会有两个 bit 对应所以特殊处理一下。

- 位图法的基本原理是：使用位数组来表示某些元素是否存在，每一个 bit 位可以标记一个元素对应的 Value

## 给 40 亿个不重复的无符号整型，没排过序。如何快速判断这个数存不存在

[C++（面试题）：给 40 亿个不重复的无符号整数，没排过序，如何快速判断一个数是否在这 40 亿个数中](https://blog.csdn.net/ETalien_/article/details/90757129)

> 字典树

40 亿个数据，我们可以大概计算一下，一个数据 4 字节，那么 40 亿数据就是 160 亿字节。我们都知道 4G 大概是 42 亿九千万字节，那么 1G 大概也就是 10 亿字节，所以 160 亿字节大约就是 16G，因此要把 40 亿个数据存放到内存中需要 16G 的内存空间。

- 如果内存允许，可以先进行排序，再用二分查找进行查找

- 但是 `40` 亿个无符号整型存储在内存中需要 16G；如果用位图 40 亿个整型需要内存为 500M

- 遍历 40 个亿数字，映射到 BitMap 中，然后对于给出的数，直接判断指定的位上存在不存在即可

## 数据库里存了很多 800 电话号码，数量特别大，以至于内存放不下，如何排序，时间比空间更重要？电话号码类似于 800-810-5555

**关键**

去掉电话号码的 800 后面就是 7 位的十进制整数，每个整数都有可能出现而且不会重复出现，可以采用各种排序算法对这些数据进行排序，但时间复杂度都在 `O(NlogN)` 及以上

**解法**

因每个七位以内的整数都有可能出现，可以用 `1bit` 来标示电话号是否出现，遍历整个电话号序列，设置相应的位，遍历位图收集位被设置的号码即可。

**扩展**

对于上述问题，每个电话号码最多出现一次，如果关键字可能多次重复出现，但关键字范围比较确定且很集中的情况下，也可使用位图（根据关键字最多可能出现的次数确定每个关键字需要的位数），但此时的位图通常会是一个整型数组，数组内容为对应位置关键字出现的次数，在执行收集过程时，对于每个关键字要收集多次（根据数组的值确定）。如有一大批职工的年龄信息，需要对这些职工按照年龄信息进行排序，则只需要建立一个长度为 100 的数组，每个数组为对应年龄人的个数，扫描一遍数组，收集年龄信息即可。

## 五个文件每个文件一亿的数据，内存无法读取出来，请统计五亿号码不同的号码的计数

[已知某个文件内包含一些电话号码，每个号码为 8 位数字，统计不同号码的个数](https://blog.csdn.net/gamesofsailing/article/details/18001703)

8 位最多 99 999 999，大概需要 99 MB，大概 10 几 M 字节的内存即可。（可以理解为从 0 - 99999999 的数字，每个数字对应一个 Bit 位，所以只需要 99M 个 Bit == 1.2 MBytes，这样，就用了小小的 1.2M 左右的内存表示了所有的 8 位数的电话）

## 假设我们有 1 亿个整数，数据范围是从 1 到 10 亿，如何快速并且省内存地给这 1 亿个数据从小到大排序

**传统做法**

1 亿个整数，存储需要 400M 空间

**位图法排序**

数字范围是 1 到 10 亿，用位图存储 125M 就够了，然后将 1 亿个数字依次添加到位图中，再将位图按下标从小到大输出值为 1 的下标，排序就完成了，时间复杂度为 O(n)

## 一个文本文件，约一万行，每行一个词，统计出其中最频繁的 10 个词，给出思想及时间复杂度分析

[一个文本文件，约一万行，每行一个词，统计出其中最频繁的 10 个词，给出思想及时间复杂度分析](https://blog.csdn.net/gamesofsailing/article/details/18040583)

> 字典树

- 建立 Trie 树，记录每颗树的出现次数，`O(n*le)`; `le`:平均查找长度

- 维护一个 10 的小顶堆，`O(n*lg10)`

- 总复杂度： `O(n*le) + O(n*lg10)`

## 从两个文件各有 50 亿条数据的文件中找出相同的 URL

[从两个文件各有 50 亿条数据的文件中找出相同的 URL](https://blog.csdn.net/qingdujun/article/details/82343756)

单机处理海量数据的大体主流思想是采取`分而治之`的方法, 将海量数据切分为若干小份来进行处理, 并且在处理的过程中要兼顾内存的使用情况和处理并发量情况
